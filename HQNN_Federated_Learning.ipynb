{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a-8nPjNubye",
        "outputId": "5e4bb341-3fa1-4d39-f2a1-902245820e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Collecting pennylane\n",
            "  Downloading pennylane-0.43.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.3)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray==0.8.0 (from pennylane)\n",
            "  Downloading autoray-0.8.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.43 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.43->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.30.0.7-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2025.10.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Downloading pennylane-0.43.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.8.0-py3-none-any.whl (934 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m934.3/934.3 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.30.0.7-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.8.0 diastatic-malt-2.15.2 pennylane-0.43.1 pennylane-lightning-0.43.0 rustworkx-0.17.1 scipy-openblas32-0.3.30.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision pennylane matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import pennylane as qml\n",
        "import numpy as np\n",
        "import time\n",
        "import copy\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EAq_n-vEd9d",
        "outputId": "1b12c0bd-0793-4749-934c-72e57c4c222f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pennylane/__init__.py:209: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.7.2 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- 0. GLOBAL CONFIGURATION ---"
      ],
      "metadata": {
        "id": "tpYAP_Y1Ef5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits = 4\n",
        "batch_size = 4\n",
        "target_classes = [1, 9] # 1=Automobile, 9=Truck\n",
        "local_epochs = 1\n",
        "learning_rate = 0.005\n",
        "\n",
        "# --- FEDERATED CONFIGURATION (Phase 2) ---\n",
        "num_clients = 10\n",
        "federated_rounds = 15\n",
        "client_participation_rate = 0.5\n",
        "\n",
        "# --- DEVICE SETUP ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Hybrid QNN Configuration: {n_qubits} Qubits\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtw9rdggEfLd",
        "outputId": "f301fe6e-986a-415b-a8df-5d0342b081c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Hybrid QNN Configuration: 4 Qubits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "#                             DATA PREPARATION\n",
        "# ----------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "Bt0lzwm3EoKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard ResNet normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def filter_data(dataset, targets):\n",
        "    \"\"\"Filters a dataset to keep only images with labels in targets.\"\"\"\n",
        "    indices = [i for i, label in enumerate(dataset.targets) if label in targets]\n",
        "    subset = torch.utils.data.Subset(dataset, indices)\n",
        "    return subset\n",
        "\n",
        "# Download CIFAR-10\n",
        "trainset_full = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset_full = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Filter the datasets for only Cars and Trucks\n",
        "trainset = filter_data(trainset_full, target_classes)\n",
        "testset = filter_data(testset_full, target_classes)\n",
        "\n",
        "# --- Phase 1: CENTRALIZED DATA LOADERS (The \"Walk\" Baseline) ---\n",
        "# Used for the centralized training loop only\n",
        "central_trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Global Test Loader (Used by both phases for consistent evaluation)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "print(f\"Filtered Dataset Ready. Total train images: {len(trainset)}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JXcMrx8EsKm",
        "outputId": "142083de-ec03-401a-e921-45566907a8b6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 30.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Dataset Ready. Total train images: 10000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Phase 2: NON-IID DATA SHARDING FOR CLIENTS (The \"Run\" HQFL) ---"
      ],
      "metadata": {
        "id": "K5wE336iEzF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_non_iid_clients(dataset, num_clients, batch_size):\n",
        "    \"\"\"Splits the dataset indices into num_clients partitions with non-IID skew.\"\"\"\n",
        "\n",
        "    label_to_indices = defaultdict(list)\n",
        "    # 1=Car maps to 0, 9=Truck maps to 1.\n",
        "    filtered_labels = np.array([1 if dataset.dataset.targets[i] == 9 else 0 for i in dataset.indices])\n",
        "\n",
        "    for i, label in enumerate(filtered_labels):\n",
        "        label_to_indices[label].append(dataset.indices[i])\n",
        "\n",
        "    all_indices = label_to_indices[0] + label_to_indices[1]\n",
        "\n",
        "    client_indices = defaultdict(list)\n",
        "    indices_per_class = [len(label_to_indices[0]), len(label_to_indices[1])]\n",
        "\n",
        "    # Skewing logic: Clients 0-4 get more of class 0 (Car), Clients 5-9 get more of class 1 (Truck)\n",
        "    for i in range(num_clients):\n",
        "        major_class = 0 if i < num_clients // 2 else 1\n",
        "        minor_class = 1 - major_class\n",
        "\n",
        "        num_samples = len(all_indices) // num_clients\n",
        "        major_samples = int(num_samples * 0.8)\n",
        "        minor_samples = num_samples - major_samples\n",
        "\n",
        "        # Simple slicing to distribute data\n",
        "        start_major = (i % (num_clients // 2)) * (indices_per_class[major_class] // (num_clients // 2))\n",
        "        end_major = start_major + major_samples\n",
        "\n",
        "        start_minor = (i % (num_clients // 2)) * (indices_per_class[minor_class] // (num_clients // 2))\n",
        "        end_minor = start_minor + minor_samples\n",
        "\n",
        "        major_indices_list = label_to_indices[major_class][start_major:end_major]\n",
        "        minor_indices_list = label_to_indices[minor_class][start_minor:end_minor]\n",
        "\n",
        "        client_indices[i].extend(major_indices_list)\n",
        "        client_indices[i].extend(minor_indices_list)\n",
        "\n",
        "    # Convert indices to DataLoader objects\n",
        "    client_dataloaders = {}\n",
        "    for i in range(num_clients):\n",
        "        # We need to pass the full original dataset to the Subset constructor\n",
        "        subset = torch.utils.data.Subset(dataset.dataset, client_indices[i])\n",
        "        client_dataloaders[i] = torch.utils.data.DataLoader(subset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return client_dataloaders\n",
        "\n",
        "# Create the Non-IID Client DataLoaders for Phase 2\n",
        "client_dataloaders = create_non_iid_clients(trainset, num_clients, batch_size)\n",
        "client_ids = list(range(num_clients))\n",
        "print(f\"Created {num_clients} Non-IID client dataloaders for Federated Simulation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c1Xc9-xExKV",
        "outputId": "de1c7bb1-3b2c-46fb-a4fd-9b2a9fb44bfc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 10 Non-IID client dataloaders for Federated Simulation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ----------------------------------------------------------------------\n",
        "#                           HYBRID QNN ARCHITECTURE\n",
        "# ----------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "8OozgcpVFOCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_circuit(inputs, weights):\n",
        "    # Angle Embedding (Encodes the 4 classical features into 4 qubits)\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "\n",
        "    # Basic Entangler Layers (The \"Thinking\" Part)\n",
        "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "\n",
        "    # Measurement (Expectation values of PauliZ map to class probabilities)\n",
        "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
        "\n",
        "class HybridResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HybridResNet, self).__init__()\n",
        "\n",
        "        # A. CLASSICAL TRANSFER LEARNING PART (Encoder)\n",
        "        self.resnet = torchvision.models.resnet18(pretrained=True)\n",
        "        for param in self.resnet.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Reduce 512 features to n_qubits (4)\n",
        "        self.fc_reduce = nn.Linear(512, n_qubits)\n",
        "\n",
        "        # B. QUANTUM PART (Core)\n",
        "        weight_shapes = {\"weights\": (3, n_qubits)}\n",
        "        self.q_layer = qml.qnn.TorchLayer(quantum_circuit, weight_shapes)\n",
        "\n",
        "        # C. FINAL PREDICTION (Decoder)\n",
        "        self.final_layer = nn.Linear(n_qubits, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Classical feature extraction and pooling layers\n",
        "        x = self.resnet.conv1(x); x = self.resnet.bn1(x); x = self.resnet.relu(x); x = self.resnet.maxpool(x)\n",
        "        x = self.resnet.layer1(x); x = self.resnet.layer2(x); x = self.resnet.layer3(x); x = self.resnet.layer4(x)\n",
        "        x = self.resnet.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Dimension Reduction\n",
        "        x_reduced = torch.tanh(self.fc_reduce(x)) * (np.pi / 2.0)\n",
        "\n",
        "        # Quantum Processing\n",
        "        x_q = self.q_layer(x_reduced)\n",
        "\n",
        "        # Final Classify\n",
        "        x = self.final_layer(x_q)\n",
        "        return x"
      ],
      "metadata": {
        "id": "afoDv2tDFQ-V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "#                           UTILITY FUNCTIONS\n",
        "# ----------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "7Pv66HihFTW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_model_accuracy(model, dataloader, device):\n",
        "    \"\"\"Evaluates the model on the full test set.\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            # Remap labels: 1(Car)->0, 9(Truck)->1\n",
        "            binary_labels = torch.where(labels == 1, 0, 1).to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += binary_labels.size(0)\n",
        "            correct += (predicted == binary_labels).sum().item()\n",
        "\n",
        "    return 100 * correct / total"
      ],
      "metadata": {
        "id": "tPBSad8rFWTE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def client_update(model, dataloader, criterion, learning_rate, device):\n",
        "    \"\"\"Performs one local training epoch and returns the updated model weights.\"\"\"\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Remap labels: 1(Car)->0, 9(Truck)->1\n",
        "        binary_labels = torch.where(labels == 1, 0, 1).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, binary_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return model.state_dict()"
      ],
      "metadata": {
        "id": "IkpzipsDFYAc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def server_aggregate(global_model, client_weights):\n",
        "    \"\"\"Averages the weights of the client models (FedAvg), skipping integer buffers.\"\"\"\n",
        "\n",
        "    global_state_dict = global_model.state_dict()\n",
        "    num_clients = len(client_weights)\n",
        "\n",
        "    for k in global_state_dict.keys():\n",
        "        # --- FIX: Check tensor data type ---\n",
        "        # Skip aggregation (division) for integer tensors (like num_batches_tracked)\n",
        "        if global_state_dict[k].dtype == torch.long or global_state_dict[k].dtype == torch.int:\n",
        "            continue\n",
        "\n",
        "        # 1. Reset the global parameter to zero before summing\n",
        "        global_state_dict[k] = torch.zeros_like(global_state_dict[k])\n",
        "\n",
        "        # 2. Sum all client weights\n",
        "        for client_sd in client_weights:\n",
        "            global_state_dict[k].add_(client_sd[k])\n",
        "\n",
        "        # 3. Average the weights\n",
        "        global_state_dict[k].div_(num_clients)\n",
        "\n",
        "    global_model.load_state_dict(global_state_dict)\n",
        "    return global_model"
      ],
      "metadata": {
        "id": "J7t2aLJhFZYF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "#                  PHASE 1: CENTRALIZED BASELINE\n",
        "# ----------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "f9v-oSR-Fh2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"             PHASE 1: CENTRALIZED HYBRID BASELINE (WALK)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "central_model = HybridResNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(central_model.parameters(), lr=learning_rate)\n",
        "n_epochs = 3 # Run 5 epochs for the baseline\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    central_model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(central_trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Remap labels: 1(Car)->0, 9(Truck)->1\n",
        "        binary_labels = torch.where(labels == 1, 0, 1).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = central_model(inputs)\n",
        "        loss = criterion(outputs, binary_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Evaluate accuracy after each epoch\n",
        "    acc = test_model_accuracy(central_model, testloader, device)\n",
        "    print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {running_loss / len(central_trainloader):.4f}, Test Accuracy: {acc:.2f}%\")\n",
        "\n",
        "final_central_acc = test_model_accuracy(central_model, testloader, device)\n",
        "print(f\"\\n--- Phase 1 Complete. Final Centralized Accuracy: {final_central_acc:.2f}% ---\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"              PHASE 2: FEDERATED HYBRID QNN (RUN)\")\n",
        "print(\"=\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7AwbWi3FdRd",
        "outputId": "cf6837ef-7df4-463f-a10a-2de15c093100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "             PHASE 1: CENTRALIZED HYBRID BASELINE (WALK)\n",
            "==================================================\n",
            "Epoch 1/3, Loss: 0.5290, Test Accuracy: 90.65%\n",
            "Epoch 2/3, Loss: 0.4365, Test Accuracy: 91.25%\n",
            "Epoch 3/3, Loss: 0.4391, Test Accuracy: 90.05%\n",
            "\n",
            "--- Phase 1 Complete. Final Centralized Accuracy: 90.05% ---\n",
            "\n",
            "==================================================\n",
            "              PHASE 2: FEDERATED HYBRID QNN (RUN)\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "#                  PHASE 2: FEDERATED TRAINING (RUN)\n",
        "# ----------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "HV5OWZBaFliU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"              PHASE 2: FEDERATED HYBRID QNN     \")\n",
        "print(\"==================================================\")\n",
        "\n",
        "# Initialize a FRESH global model\n",
        "global_model = HybridResNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f\"Rounds: {federated_rounds}, Participation: {client_participation_rate*100}%, Clients: {num_clients}\")\n",
        "\n",
        "start_time_federated = time.time()\n",
        "\n",
        "for round_num in range(federated_rounds):\n",
        "\n",
        "    # 1. Server Selects Clients\n",
        "    participating_clients = np.random.choice(client_ids,\n",
        "                                             max(1, int(num_clients * client_participation_rate)),\n",
        "                                             replace=False)\n",
        "\n",
        "    client_weights = []\n",
        "\n",
        "    # 2. Clients Train Locally\n",
        "    for client_id in participating_clients:\n",
        "\n",
        "\n",
        "        # A. Initialize a fresh local model (gets a fresh, unproblematic PennyLane device)\n",
        "        local_model = HybridResNet().to(device)\n",
        "\n",
        "        # B. Load the global weights (state_dict) into the local model\n",
        "\n",
        "        local_model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "        # Perform local update (1 local epoch)\n",
        "        weights = client_update(\n",
        "            local_model,\n",
        "            client_dataloaders[client_id],\n",
        "            criterion,\n",
        "            learning_rate,\n",
        "            device\n",
        "        )\n",
        "\n",
        "        client_weights.append(weights)\n",
        "\n",
        "    # 3. Server Aggregates\n",
        "    global_model = server_aggregate(global_model, client_weights)\n",
        "\n",
        "    # 4. Evaluate Global Model\n",
        "    global_acc = test_model_accuracy(global_model, testloader, device)\n",
        "\n",
        "    print(f\"[Round {round_num + 1}/{federated_rounds}] Global Test Accuracy: {global_acc:.2f}%\")\n",
        "\n",
        "end_time_federated = time.time()\n",
        "print(f\"\\n--- Phase 2 Complete. Final Federated Accuracy: {global_acc:.2f}% (Time: {end_time_federated - start_time_federated:.2f}s) ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxIwD4dpF45-",
        "outputId": "cd24330e-267b-4713-f22f-03e2e9d00609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "              PHASE 2: FEDERATED HYBRID QNN     \n",
            "==================================================\n",
            "Rounds: 15, Participation: 50.0%, Clients: 10\n",
            "[Round 1/15] Global Test Accuracy: 49.35%\n",
            "[Round 2/15] Global Test Accuracy: 50.00%\n",
            "[Round 3/15] Global Test Accuracy: 50.00%\n",
            "[Round 4/15] Global Test Accuracy: 51.25%\n",
            "[Round 5/15] Global Test Accuracy: 51.20%\n",
            "[Round 6/15] Global Test Accuracy: 54.25%\n",
            "[Round 7/15] Global Test Accuracy: 87.55%\n",
            "[Round 8/15] Global Test Accuracy: 89.30%\n",
            "[Round 9/15] Global Test Accuracy: 88.10%\n",
            "[Round 10/15] Global Test Accuracy: 90.60%\n",
            "[Round 11/15] Global Test Accuracy: 90.75%\n",
            "[Round 12/15] Global Test Accuracy: 91.15%\n",
            "[Round 13/15] Global Test Accuracy: 89.65%\n",
            "[Round 14/15] Global Test Accuracy: 90.55%\n",
            "[Round 15/15] Global Test Accuracy: 90.20%\n",
            "\n",
            "--- Phase 2 Complete. Final Federated Accuracy: 90.20% (Time: 1950.80s) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def SPSA_Optimizer(model, criterion, inputs, labels, lr, c):\n",
        "\n",
        "    # 1. Create the perturbation vector 'delta' (random sign for each parameter)\n",
        "    delta = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            # Random sign (+1 or -1) for each parameter, scaled by c\n",
        "            delta[name] = (2 * torch.randint(0, 2, param.shape).to(param.device) - 1.0) * c\n",
        "\n",
        "    # 2. Forward pass for f(w + c*delta) (Positive Perturbation)\n",
        "    # Apply positive perturbation\n",
        "    for name, param in model.named_parameters():\n",
        "        if name in delta:\n",
        "            param.data.add_(delta[name])\n",
        "\n",
        "    outputs_plus = model(inputs)\n",
        "    loss_plus = criterion(outputs_plus, labels)\n",
        "\n",
        "    # 3. Forward pass for f(w - c*delta) (Negative Perturbation)\n",
        "    # Apply negative perturbation (subtract 2 * c * delta from the current state w + c*delta)\n",
        "    for name, param in model.named_parameters():\n",
        "        if name in delta:\n",
        "            param.data.sub_(2 * delta[name])\n",
        "\n",
        "    outputs_minus = model(inputs)\n",
        "    loss_minus = criterion(outputs_minus, labels)\n",
        "\n",
        "    # The approximate gradient is (f(w+c*delta) - f(w-c*delta)) / (2*c*delta)\n",
        "\n",
        "    # Calculate the change in loss\n",
        "    loss_diff = loss_plus - loss_minus\n",
        "\n",
        "    # Restore the model to its original state (w_k) before the update\n",
        "    for name, param in model.named_parameters():\n",
        "        if name in delta:\n",
        "\n",
        "            param.data.add_(delta[name])\n",
        "\n",
        "            # SPSA estimate: g_k = loss_diff / (2 * delta)\n",
        "            gradient_estimate = loss_diff / (2.0 * delta[name])\n",
        "\n",
        "            # Update: w_k+1 = w_k - lr * g_k\n",
        "            update = lr * gradient_estimate\n",
        "            param.data.sub_(update)\n",
        "\n",
        "    return (loss_plus.item() + loss_minus.item()) / 2.0"
      ],
      "metadata": {
        "id": "PYNboVgzjwcm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def client_update_spsa(model, dataloader, criterion, learning_rate, device, c_spsa=0.01):\n",
        "    model.train()\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        binary_labels = torch.where(labels == 1, 0, 1).to(device)\n",
        "\n",
        "        SPSA_Optimizer(\n",
        "            model,\n",
        "            criterion,\n",
        "            inputs,\n",
        "            binary_labels,\n",
        "            learning_rate,\n",
        "            c_spsa # Perturbation size (a fixed small number)\n",
        "        )\n",
        "\n",
        "    return model.state_dict()"
      ],
      "metadata": {
        "id": "DixHaU72j73O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "#             PHASE 3: HQFL with SPSA (Noise Resilience Test)\n",
        "# ----------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "wTVpP2E1kKa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def client_update_spsa(model, dataloader, criterion, learning_rate, device, c_spsa=0.05):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        binary_labels = torch.where(labels == 1, 0, 1).to(device)\n",
        "\n",
        "        # SPSA does not use PyTorch's automatic backward() or optimizer.step()\n",
        "        SPSA_Optimizer(\n",
        "            model,\n",
        "            criterion,\n",
        "            inputs,\n",
        "            binary_labels,\n",
        "            learning_rate,\n",
        "            c_spsa # Perturbation size\n",
        "        )\n",
        "        # ... rest of the function remains the same\n",
        "    return model.state_dict()"
      ],
      "metadata": {
        "id": "NgmBlXJw1HJK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"              PHASE 3: HQFL + SPSA OPTIMIZER\")\n",
        "print(\"==================================================\")\n",
        "\n",
        "global_model_spsa = HybridResNet().to(device) # Initialize a FRESH global model\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f\"Rounds: {federated_rounds}, Optimizer: SPSA, Clients: {num_clients}\")\n",
        "\n",
        "start_time_spsa = time.time()\n",
        "\n",
        "for round_num in range(federated_rounds):\n",
        "\n",
        "    # 1. Server Selects Clients\n",
        "    participating_clients = np.random.choice(client_ids,\n",
        "                                             max(1, int(num_clients * client_participation_rate)),\n",
        "                                             replace=False)\n",
        "\n",
        "    client_weights = []\n",
        "\n",
        "    # 2. Clients Train Locally\n",
        "    for client_id in participating_clients:\n",
        "\n",
        "        # Clone global weights to local model\n",
        "        local_model = HybridResNet().to(device)\n",
        "        local_model.load_state_dict(global_model_spsa.state_dict())\n",
        "\n",
        "        # --- CALL THE SPSA UPDATE FUNCTION ---\n",
        "        weights = client_update_spsa(\n",
        "            local_model,\n",
        "            client_dataloaders[client_id],\n",
        "            criterion,\n",
        "            learning_rate,\n",
        "            device\n",
        "        )\n",
        "\n",
        "        client_weights.append(weights)\n",
        "\n",
        "    # 3. Server Aggregates (using the same FedAvg logic)\n",
        "    global_model_spsa = server_aggregate(global_model_spsa, client_weights)\n",
        "\n",
        "    # 4. Evaluate Global Model\n",
        "    global_acc = test_model_accuracy(global_model_spsa, testloader, device)\n",
        "\n",
        "    print(f\"[Round {round_num + 1}/{federated_rounds}] SPSA Global Test Accuracy: {global_acc:.2f}%\")\n",
        "\n",
        "end_time_spsa = time.time()\n",
        "print(f\"\\n--- Phase 3 Complete. Final SPSA Accuracy: {global_acc:.2f}% (Time: {end_time_spsa - start_time_spsa:.2f}s) ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r7YGKRYkIT_",
        "outputId": "74084da4-17a9-4416-e4f2-41d282f78b2a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "              PHASE 3: HQFL + SPSA OPTIMIZER\n",
            "==================================================\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 156MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rounds: 15, Optimizer: SPSA, Clients: 10\n",
            "[Round 1/15] SPSA Global Test Accuracy: 50.00%\n",
            "[Round 2/15] SPSA Global Test Accuracy: 50.00%\n",
            "[Round 3/15] SPSA Global Test Accuracy: 50.65%\n",
            "[Round 4/15] SPSA Global Test Accuracy: 54.15%\n",
            "[Round 5/15] SPSA Global Test Accuracy: 49.90%\n",
            "[Round 6/15] SPSA Global Test Accuracy: 49.95%\n",
            "[Round 7/15] SPSA Global Test Accuracy: 63.10%\n",
            "[Round 8/15] SPSA Global Test Accuracy: 56.60%\n",
            "[Round 9/15] SPSA Global Test Accuracy: 60.10%\n",
            "[Round 10/15] SPSA Global Test Accuracy: 59.45%\n",
            "[Round 11/15] SPSA Global Test Accuracy: 62.65%\n",
            "[Round 12/15] SPSA Global Test Accuracy: 63.25%\n",
            "[Round 13/15] SPSA Global Test Accuracy: 70.50%\n",
            "[Round 14/15] SPSA Global Test Accuracy: 68.15%\n",
            "[Round 15/15] SPSA Global Test Accuracy: 71.15%\n",
            "\n",
            "--- Phase 3 Complete. Final SPSA Accuracy: 71.15% (Time: 1123.11s) ---\n"
          ]
        }
      ]
    }
  ]
}